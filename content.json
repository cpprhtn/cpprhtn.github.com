{"pages":[{"title":"about","text":"","link":"/about/index.html"}],"posts":[{"title":"Hello World","text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new &quot;My New Post&quot; More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment","link":"/2022/01/09/hello-world/"},{"title":"Installing hadoop on MAC OS M1","text":"M1 맥북에서 하둡 환경을 구성하다보니 수많은 블로그를 참고하였고, 설명이 제각각이라 그대로 따라만 하면 설치할 수 있도록 정리해보았습니다. 1. Java JDK 설치Java JDK는 intel용을 설치하면 로제타2를 통해 돌아가므로 M1칩에서 네이티브로 돌아가는 Azul의 OpenJDK(download)를 설치하면 됩니다. java-8 lts / mac os / arm64 옵션이 맞는지 확인하고나서 .tar.gz 파일을 다운받고, 다운받은 파일을 더블클릭하여 실행시키면 설치가 진행됩니다. 이후에 터미널창을 열고 아래와 같이 Java path를 설정하시면 됩니다. 1234567cd ~vi ~/.zshrc export JAVA_HOME=/Library/Java/JavaVirtualMachines/zulu-8.jdk/Contents/Home/sourse ~/.zshrc java -version을 입력했을때 아래와 비슷한 결과가 나오면 제대로 설치된것입니다. 1234cpprhtn@cpprhtn-MacBookPro ~ % java -versionopenjdk version &quot;1.8.0_312&quot;OpenJDK Runtime Environment (Zulu 8.58.0.13-CA-macos-aarch64) (build 1.8.0_312-b07)OpenJDK 64-Bit Server VM (Zulu 8.58.0.13-CA-macos-aarch64) (build 25.312-b07, mixed mode) 2. Hadoop을 구축할 계정 생성하둡을 구축할 계정을 생성할 것입니다. 여러분이 현재 작업하던 환경과 같은 공간에서 하둡 환경을 구축하다가 예상치 못한 일이 발생했을때 복구하기 어려우므로 새로운 환경에서 환경을 구축하는 것입니다. 먼저 시스템 환경설정 -&gt; 사용자 및 그룹에 들어와 자물쇠를 풀어줍니다. 이후 ‘+’ 버튼을 눌러 사용자 계정을 하나 만들어줍니다. 여러분이 만든 사용자에 대하여 사용자를 이 컴퓨터의 관리자로 허용을 체크하여 관리자권한을 부여합니다. 관리자 권한을 주지 않으면 이후에 하둡 파일을 수정할때 접근권한이 없다고 뜹니다. 아직 재부팅에 들어가지 마세요 바로 이어서 시스템 환경설정 -&gt; 공유에 들어와 원격 로그인버튼을 체크해줍니다. 이제 시스템을 재부팅해 줄것인데, 여러분이 원래 작업하던 계정으로 다시 로그인하여 터미널을 오픈합니다. 새로 만들어준 계정으로 로그인 X 현재 사용하는 계정에서 새로 만든 계정으로 로그인합시다. 123su [새 계정][새 계정 password] 3. SSH 활성화로컬 호스트에 SSH로 연결할 수 있도록 보안 키를 만들고 암호없이 사용할 수 있도록 키를 복사하여 권한을 제한해줍니다. 12345678910111213141516# 새 계정의 home 디렉토리로 이동cd ~# 키생성ssh-keygen -t rsa -P '' -f ~/.ssh/id_rsa# 키복사cat ~/.ssh/id_rsa.pub &gt;&gt; ~/.ssh/authorized_keys# 권한 제한chmod 0600 ~/.ssh/id_rsa.pub# 작동여부 확인 후 종료ssh localhostexit 4. Apache Hadoop 설치하둡을 설치할텐데, 두가지 방법으로 설치가 가능합니다. 직접 다운받은후 경로 이동 Hadoop page에서 binary-aarch64 파일을 다운로드합니다. 다운받은 파일을 더블클릭하여 압축을 풀어줍니다. 압축이 풀린 파일을 새 계정의 home 디렉토리로 이동시켜줍니다. 1mv /Users/원래계정명/Downloads/hadoop-3.3.1 ~/ homebrew의 wget를 이용하여 간편설치 homebrew가 설치되어있는 사람은 아래 코드를 이용하여 바로 설치가 가능합니다. homebrew를 설치했고 잘 쓰고계시던 분들이 있을것입니다. 하지만 해당 포스트를 따라하면 새 계정을 만들어 작업하므로 새 게정의 home path의 .zshrc파일에서 homebrew path 설정이 안되어있을것입니다. 이런 경우에는 새 터미널 창을 하나켜서 본래 계정의 homebrew path를 카피하여 추가해주시기를 바랍니다.필자의 path는 아래와 같으며 여러분들도 이와 비슷한 경로일 것입니다. 1export PATH=/opt/homebrew/bin:$PATH 12345678# 다운로드wget https://downloads.apache.org/hadoop/common/hadoop-3.3.1/hadoop-3.3.1.tar.gz# 압축해제tar xzf hadoop-3.3.1.tar.gz# 압축파일 제거rm -rf hadoop-3.3.1.tar.gz 5. Hadoop settinglocal에서 하둡을 세팅하기 위해서는 몇가지 파일을 수정해주어야합니다. 먼저 .zshrc 파일을 수정해줍니다. 12345678910111213141516cd ~vi ~/.zshrc export HADOOP_HOME=/home/새 계정/hadoop-3.2.1 export HADOOP_INSTALL=$HADOOP_HOME export HADOOP_MAPRED_HOME=$HADOOP_HOME export HADOOP_COMMON_HOME=$HADOOP_HOME export HADOOP_HDFS_HOME=$HADOOP_HOME export YARN_HOME=$HADOOP_HOME export HADOOP_COMMON_LIB_NATIVE_DIR=$HADOOP_HOME/lib/native export PATH=$PATH:$HADOOP_HOME/sbin:$HADOOP_HOME/bin export HADOOP_OPTS&quot;-Djava.library.path=$HADOOP_HOME/lib/native&quot;source ~/.zshrc .zshrc에 추가되는 파일의 첫번째 export 라인의 path는 꼭 수정해줍시다. (새 계정명으로) hadoop-env.sh 파일 편집이후 hadoop-env.sh 파일에서 아래와 같이 주석되어있는부분을 주석을 해제하고 JAVA_HOME path를 세팅해줍니다. export JAVA_HOME=필자는 ~/.zshrc에서 이미 세팅해두었기때문에 해당 파일은 추가코드 없이 그냥 넘어갔습니다. 1234vi $HADOOP_HOME/etc/hadoop/hadoop-env.sh export JAVA_HOME=/Library/Java/JavaVirtualMachines/zulu-8.jdk/Contents/Home/ core-site.xml 파일 편집HDFS와 하둡의 핵심 속성을 정의해줍니다. 새 계정 이름으로 경로를 설정해줍시다. 1234567891011121314151617181920vi $HADOOP_HOME/etc/hadoop/core-site.xml &lt;configuration&gt; &lt;property&gt; &lt;name&gt;hadoop.tmp.dir&lt;/name&gt; &lt;value&gt;/Users/새 계정/hdfs/tmp/&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;fs.default.name&lt;/name&gt; &lt;value&gt;hdfs://127.0.0.1:9000&lt;/value&gt; &lt;/property&gt; &lt;/configuration&gt;cd ~mkdir hdfscd hdfsmkdir tmp hdfs-site.xml 파일 편집hdfs-site.xml 파일은 노드 메타데이터, fsimage 파일 및 편집 로그 파일을 저장할 위치를 제어합니다. NameNode 및 DataNode 스토리지 디렉토리를 정의합니다. 새 계정 이름으로 경로를 설정해줍시다. value값에 설정된 숫자는 1~3으로 설정됩니다. 1은 로컬환경, 2는 가상 분할환경, 3은 완전 분할환경을 의미합니다. 이 포스트에서는 로컬환경을 구축하고 있으므로 value값은 1을 부여하였습니다. 123456789101112131415161718192021222324vi $HADOOP_HOME/etc/hadoop/hdfs-site.xml &lt;configuration&gt; &lt;property&gt; &lt;name&gt;dfs.data.dir&lt;/name&gt; &lt;value&gt;/Users/새 계정/hdfs/namenode&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.data.dir&lt;/name&gt; &lt;value&gt;/Users/새 계정/hdfs/datanode&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.replication&lt;/name&gt; &lt;value&gt;1&lt;/value&gt; &lt;/property&gt; &lt;/configuration&gt;cd ~cd hdfsmkdir namenodemkdir datanode mapred-site.xml 파일 편집MapReduce 값을 정의할 수 있습니다. MapReduce 프레임워크 이름을 지정해주었습니다. 12345678vi $HADOOP_HOME/etc/hadoop/mapred-site.xml &lt;configuration&gt; &lt;property&gt; &lt;name&gt;mapreduce.framework.name&lt;/name&gt; &lt;value&gt;yarn&lt;/value&gt; &lt;/property&gt; &lt;/configuration&gt; yarn-site.xml 파일 편집여기에는 노드 관리자, 리소스 관리자, 컨테이너 및 애플리케이션 마스터에 대해 설정해줍니다. 코드가 길어도 수정할 부분은 없으니 복붙하여 쓰시면 될듯합니다. 123456789101112131415161718192021222324vi $HADOOP_HOME/etc/hadoop/yarn-site.xml &lt;configuration&gt; &lt;property&gt; &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt; &lt;value&gt;mapreduce_shuffle&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;yarn.nodemanager.aux-services.mapreduce.shuffle.class&lt;/name&gt; &lt;value&gt;org.apache.hadoop.mapred.ShuffleHandler&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;yarn.resourcemanager.hostname&lt;/name&gt; &lt;value&gt;127.0.0.1&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;yarn.acl.enable&lt;/name&gt; &lt;value&gt;0&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;yarn.nodemanager.env-whitelist&lt;/name&gt; &lt;value&gt;JAVA_HOME,HADOOP_COMMON_HOME,HADOOP_HDFS_HOME,HADOOP_CONF_DIR,CLASSPATH_PERPEND_DISTCACHE,HADOOP_YARN_HOME,HADOOP_MAPRED_HOME&lt;/value&gt; &lt;/property&gt; &lt;/configuration&gt; 6. HDFS namenode formatHadoop 서비스를 처음 시작하기 전에 namenode를 포맷하는 것이 중요합니다. 123cd ~hdfs namenode -format 7. Hadoop 시작이전에 .zshrc에서 경로세팅을 했으므로 홈 디렉토리에서 아래와 같은 코드를 이용하여 하둡 서비스를 실행 및 종료 시킬 수 있습니다. 1234567891011cd ~# 모든 하둡 구성요소 실행start-all.sh# 실행 중인 모든 프로세스의 목록 확인jps# 모든 하둡 구성요소 종료stop-all.sh 우선은 start-all.sh을 실행시킨 후 10초정도 기다리면 하둡 구성요소들이 작동됩니다. 이후에 jps명령을 실행시키면 아래 사진과 같이 최소한 6개의 서비스가 표시되어야 합니다. (표시되는 순서나 넘버는 상관없음) 8. 브라우저에서 Hadoop UI에 액세스인터넷 브라우저를 열은 후에 localhost URL로 이동한 후 포트 번호를 사용하여 Hadoop UI에 접근할 수 있습니다. 9870 : NameNode 사용자 인터페이스 [전체 클러스터에 대한 포괄적인 개요를 제공] 9864 : DataNode 사용자 인터페이스 [브라우저에서 직접 개별 DataNode에 접근하는데 사용] 8088 : YARN Resource Manager [하둡 클러스터에서 실행 중인 모든 프로세스를 모니터링 할 수 있음] http://localhost:9870 http://localhost:9870 http://localhost:9870","link":"/2022/01/09/Installing-Hadoop-in-mac/"},{"title":"2021년 회고록","text":"2021년은 필자의 스무살!!! 대학교 새내기로 지내던 해입니다. 하지만 코로나의 여파로 대학교 생활은 물건너 갔습니다. 늦었다 생각하여 넘어가려고 했는데, 어떤 분이 용기를 주어 쓰게 되었습니다. 연구실 활동부경대학교 (21년 1월 ~ 현재)제 부족한 AI 커리어를 보고도 같이 AI연구 해보자고 교수님께 제안을 받게 되었습니다. 당시 고등학교 졸업장도 따지 못했던 시기인데 지금 생각해보면 엄청난 운이 뒤따른것 같습니다. 당시만 해도 연구실에서 연구를 한다는것은 되게 멋있는 일이라 생각했었고, 한번 해보자는 마음으로 연구실을 다니게 되었습니다. 가볍게 시작한 마음이였지만 어느덧 1년이 훌쩍 지나왔으며, 기대했던것 보다도 좋은 성능이 나와서 만족스러운 경험이였습니다. 해당 연구실을 다니며 논문을 읽는법이나 논문에서 제안된 AI모델을 구현해보고 적용해보면서 큰 폭으로 실력이 늘게된 계기가 되었습니다. 부산대학교 (21년 4월 ~ 현재)고2때부터 알고 지내던 쌤(이제는 교수님이라 불러야하지만 이미 쌤으로 define되어버림)이 AI 논문을 준비하게 되면서 연락이 왔었습니다. 처음에는 논문에 넣을 연구를 도와주려고 연구실을 들락날락 했었는데, 매일 가다보니 연구원분들과도 친해지고, 교수님한테는 쌤 제자라고 소개받게되면서 자연스럽게 연구실을 다니게 되었습니다. 쌤의 연구를 도와주면서 frequency와 CV(Computer Version)에 대한 깊이있는 공부를 할 수 있었으며 연구실에 남아돌던 Pixhawk4 STM보드가 있어서 드론+CV 연구도 해볼 수 있었습니다. 또한 해당 연구실이 포닥 위주로 구성되어있어서 연구원분들께 많은 것을 보고 배울 수 있는 좋은 경험이였습니다. 한국교원대학교 (21년 1월)알던 형의 소개로 박사학위논문 연구에 도움이 필요하다 하여 어쩌다보니 연구에 참여하게 되었습니다. 짧은 기간동안 질문에 대한 많은 답변과 피드백을 남기며 끝이 났으며, 프로그래밍 공부방법에 대한 성찰을 가지게 된 계기가 되었습니다. 최근에 무사히 졸업하셨다는 연락을 받았으며, 참여한 논문은 아직 출판전이라 따로 우편으로 받아서 읽어도 보았습니다. 내가 낸 의견과 답변, 피드백이 논문에 반영된 모습은.. 정말 신기했습니다. 강의 활동회고를 쓰면서 강의활동도 정리해보았는데 생각보다 많더군요. 먼저 제 첫 강의는 부경대학교 대학원생을 상대로 한 인공지능 강의입니다. 인생 첫 강의여서 많이 떨렸었는데 강의를 막상 시작하니까 떨림은 어디가고 재미있어서 신나게 강의했던 기억이 납니다. 개인이 진행해보는 강의라서 모든 강의자료를 직접 다 만들어야 했던 경험은 당시에는 악몽이였고, 나중에서는 신의 한수가 됩니다. 4개월간 꾸준히 강의를 진행했으며 강의자료를 만들면서, 혹은 강의후에 들어오는 다양한 질문들에 대해 답변해주면서 AI의 기초를 더 탄탄히 다질 수 있는 기회가 되었습니다. 두 번째, 세 번째, 네 번째는 위에서 언급한 “쌤”이 하는 강의에서 보조강사로 활동하게 되었습니다. C언어와 OPENCV 강의(2번)의 보조강사로 있으면서 “쌤”이 어떻게 강의를 진행하는지, 말 안듣는 잼민이(고등학생도 잼민이겠죠?)는 어떻게 하는지 등과 같은 것들을 볼 수 있었습니다. OPENCV 강의가 기억에 남는데, 인공지능이 갑자기 뜨면서 OPENCV 강의를 잡아온거라 강의자료를.. A에서 Z까지 다 만들었습니다. Jupyter Notebook에 데이터, 이미지, 코드, 코드설명을 꼼꼼히 적고 검수하고 했다는..ㅠㅠ 마지막으로는 과학고등학교 강의를 하게 되었습니다. 강의 하기로 확정이 되자, “Tensorflow(인공지능 프레임워크) 여름캠프”라는 이름하에 강의가 진행되었고, 첫 강의였던 부경대학교 강의때 열심히 만들어 둔 자료를 기반으로 딱딱한 내용들은 빼고, 학생들이 흥미로워 할 내용들은 추가하여 강의를 진행하게 되었습니다. 생각보다 학생들이 잘 따라와주어서 재미있게(저혼자만 그렇게 생각할수 있음) 강의를 진행하였고, 강의후에 추가로 진행한 AI 팀프로젝트는 생각보다도 더 수준높은 결과물을 만들어와서 역시 과고는 괴물만 사는구나 라는 기억이 남던 경험이 되었습니다. 2022년 목표꼭 해야할 목표 몇가지만 세우고 글을 마무리 지으려고 합니다. (스스로의 다짐이려나?) Data science 공부하기 hadoop spark hive more AI 동아리 만들기 (신설학과라 AI관련 동아리가 없더라구요) 연구 잘 마무리하기 책 무사히 출판하기 스타트업(6월쯤 AI 개발팀장으로 들어갈예정) 잘 운영(?)하기 끝으로스무살, 첫 회고록을 써 보았습니다. 글을 잘 쓰는 편이 아니라 이 상태로 올려도 될지 고민이 들고, 이렇게 글을 써도 되는거 맞냐는 의문이 들지만 “어차피 볼사람도 없을텐데 고민하면 뭐하냐”라고 세뇌하며 글을 마무리합니다.","link":"/2022/01/11/2021-retrospect/"},{"title":"HDFS란?","text":"HDFS(Hadoop Distributed File System)는 수십 테라바이트 이상의 대용량 파일을 분산된 서버에 저장하고, 많은 클라이언트가 저장된 데이터를 빠르게 처리할 수 있게 설계된 파일 시스템입니다. 1. HDFS란?기존에도 DAS, NAS, SAN과 같은 대용량 파일 시스템이 있었으나 HDFS와 기존 대용량 파일 시스템의 가장 큰 차이점은 저사양 서버를 이용해 스토리지를 구성할 수 있다는 것입니다. HDFS를 사용하면 고사양 서버에 비해 매우 저렴한 저사양 서버 수십, 수백대를 묶어서 하나의 스토리지처럼 사용할 수 있으며 물리적으로는 분산된 서버의 로컬 디스크에 데이터가 저장되어있지만 HDFS에서 제공하는 API를 이용하여 파일의 읽기 및 저장을 마치 한 서버에서 작업하듯이 구성할 수 있습니다. 그렇다고 HDFS가 기존 대용량 파일 시스템을 완전히 대체하는 것은 아닙니다. 고성능, 고가용성이 필요한 경우에는 SAN을, 안정적인 파일 저장이 필요한 경우에는 NAS를 사용합니다. 또한 트랜잭션이 중요한 경우에도 HDFS가 적합하지 않으며, 대규모 데이터를 저장하거나, 배치로 처리를 하는 경우에 HDFS를 사용하면 됩니다. HDFS를 만든이유HDFS는 네 가지 목표를 가지고 설계되었습니다. 장애 복구 서버에는 다양한 장애가 발생할 수 있습니다. 이러한 서버를 수십, 수백대를 묶어서 구축한 분산 서버에는 당연히 장애가 생길 확률이 높아집니다. HDFS는 이러한 장애를 빠른 시간에 감지하고 대처할 수 있게 설계되어 있습니다. 스트리밍 방식의 데이터 접근 HDFS는 클라이언트의 요청을 빠른 시간 내에 처리하는 것보다는 동일한 시간 내에 더 많은 데이터를 처리하는 것을 목표로 합니다. 이를 위해 HDFS는 랜덤 접근 방식 대신 스트리밍 방식으로 데이터에 접근하도록 설계되어 있습니다. 대용량 데이터 저장 HDFS는 파일 하나의 크기가 테라바이트 이상의 크기로도 저장될 수 있게 설계되었습니다. 따라서 높은 데이터 전송 대역폭과, 하나의 클러스터에서 수백 대의 노드를 지원 할 수 있습니다. 또한 하나의 인스턴스에서는 수백만개 이상의 파일을 지원합니다. 데이터 무결성 HDFS에서는 한번 저장한 데이터는 더이상 수정할 수 없고, 읽기만 가능하게 하여 무결성을 유지했습니다. 하지만 데이터 수정이 불가능하다는 것은 ㅋ 하둡 초기에서부터 검토되어 왔고, 하둡 2.0 버전부터는 HDFS에 저장된 파일에 append 기능이 추가되었습니다. HDFS 아키텍처 블록 구조 파일 시스템 HDFS는 블록 구조의 파일 시스템입니다. HDFS에 저장하는 파일은 특정 크기의 블록으로 나눠져 분산된 서버에 저장합니다. 하둡의 버전에 따라서 블록 크기의 defalt 세팅값이 달라지는데, 하둡 2.0 이상버전에서는 블록당 128MB의 크기를 가지고 있습니다. 따라서 예를 들어 200MB 파일이 있다면 128MB 블록 2개를 사용하게 되며, 블록 하나는 128MB를 전부 사용하게 되며, 다른 블록하나는 128MB를 다 차지하는 것이 아니라 78MB를 차지하게 되는 형태입니다. 그렇기 때문에 데이터 크기에 상관없이 저장할 수 있습니다. 또한 HDFS에서는 기본적으로 3개의 블록 복제본을 저장하게 됩니다. 이는 특정 서버의 하드디스크에 오류가 생기더라도 복제된 블록을 사용하여 데이터를 조회할 수 있습니다. 블록의 크기와 복제본의 수는 하둡 환경설정 파일에서 변경할 수 있습니다. 네임노드와 데이터노드 네임노드네임노드는 다음과 같은 기능을 합니다. 메타데이터 관리 네임노드는 파일 시스템을 유지하기 위한 메타데이터를 관리합니다. 메타데이터는 파일시스템 이미지와 파일에 다한 블록 매핑 정보로 구성됩니다. 데이터노드 모니터링 데이터노드가 네임노드에게 3초마다 heartbeat 메시지를 전송합니다. heartbeat는 데이터노드 상태 정보와 block-report로 구성됩니다. 네임노드는 heartbeat를 이용하여 데이터노드의 실행 상태와 용량을 모니터링합니다. 일정 시간 내에 heartbeat 메시지가 들어오지않는 데이터노드가 있을 경우 장애가 발생한 서버로 판단합니다. 블록 관리 데이터노드에 장애가 발생시 해당 데이터노드의 블록을 새로운 데이터노드로 복제합니다. 용량이 부족한 데이터노드가 있다면 여유있는 데이터노드로 블록을 이동시킵니다. 블록의 복제본 수 또한 관리합니다. 클라이언트 요청 접수 클라이언트가 HDFS에 접근하려면 반드시 네임노드에 접속해야합니다. HDFS에 파일을 저장하는 경우 기존 파일의 저장 여부와 권한 확인 절차를 거쳐서 저장을 승인합니다. 또한 파일을 조회하는 경우에는 블록의 위치 정보를 반환합니다. 데이터노드데이터노드는 클라이언트가 HDFS에 저장하는 파일을 로컬 디스크에 유지합니다. 이때 로컬 디스크에 저장되는 파일은 두 종류로 구성됩니다.첫 번째 파일은 실제 데이터가 저장되어 있는 로우 데이터이며, 두 번째 파일은 체크섬이나 파일 생성 일자와 같은 메타데이터가 설정되어 있는 파일입니다. 보조네임노드 네임노드 네임노드는 메타데이터를 메모리에서 처리합니다. 하지만 메모리에만 데이터를 유지할 경우 서버가 재부팅되면 모든 메타데이터를 유실할 수 있습니다. HDFS에서는 이러한 문제점을 해결하기 위해 editslog와 fsimage라는 두 개의 파일을 생성합니다. editslog: HDFS의 모든 변경 이력을 저장한 파일.fsimage: 메모리에 저장된 메타데이터의 파일 시스템 이미지를 저장한 파일. 네임노드 작동시 네임노드가 구동되면 로컬에 저장된 fsimage와 editslog를 조회 메모리에 fsimage를 로딩해 파일시스템 이미지를 생성 메모리에 로딩된 파일 시스템 이미지에 editslogdp 기록된 변경 이력을 적용 메모리에 로딩된 파일 시스템 이미지를 이용해 fsimage 파일을 갱신 editslog 초기화 데이터노드가 전송한 플록리포트를 메모리에 로딩된 파일 시스템 이미지에 적용 보조네임노드 editslog는 별도의 크기제한이 없기때문에 무한대로 커질 수 있기 때문에 editslog의 크기가 계속해서 커지면 위 단계중 3번 단계를 진행할 때 많은 시간이 소요될 것입니다. 이러한 문제점을 해결하기 위해 HDFS는 보조네임노드라는 노드를 제공합니다. 보조네임노드는 주기적으로 네임노드의 fsimage를 갱신하는 역할을 하며, 이러한 작업을 체크포인트라고 합니다. 보조네임노드는 다음과 같은 체크포인팅 단계를 거쳐 네임노드의 fsimage를 갱신해줍니다. 이렇게 체크포인팅이 완료되면 네임노드의 fsimage는 최신 내역으로 갱신되며, editslog의 크기도 축소됩니다. 기본적으로 한시간마다 체크포인팅이 발생하며, 하둡 환경설정 파일에서 변경할 수 있습니다. 보조네임노드도 중요하다 보조네임노드를 중요하게 생각하지 않거나 보조네임노드를 네임노드의 백업 노드라고 생각할 수도 있습니다. 하지만 앞에서 설명했듯이 보조네임노드는 네임노드의 (fsimage 갱신, editslog 축소) 시켜주는 역할을 하므로 백업과는 관련이 없습니다. 또한 보조네임노드가 다운되어있어도 네임노드의 동작에는 전혀 문제가 없기때문에 보조네임노드를 방치해둘지도 모릅니다. 하지만 네임노드를 재구동하는 상황이 생겼을때, editslog의 크기가 너무 커서 네임노드의 메모리에 로딩되지 못하는 상황이 발생할 수 있습니다. 따라서 이러한 장애를 사전에 방지하기 위해서는 주기적으로 보조네임노드를 관리해주어야 합니다. HDFS Architecture","link":"/2022/01/11/About-HDFS/"},{"title":"How-to-install-Maven-on-M1","text":"&lt;&lt;시작하세요 하둡 프로그래밍&gt;&gt;이라는 책을 통해 하둡을 공부하면서, 이 책의 예제파일을 다운받고 실행을 시켜보려고 했습니다. Eclipse나 InteliJ를 사용하는 유저라면 간단한 세팅을 통하여 mvn 프로젝트를 실행시킬 수 있지만, 저는 터미널에서 package사용과 mvn명렁어를 사용하기 위해서 직접 M1 mac에 설치하게 되었습니다. Apache Maven 다운Apache Maven 주소에서 최신 버전의 .tar.gz파일을 내려받습니다. tar -vxf 명령어로 압축을 해제하거나, 다운받은 파일을 더블클릭하여 압축을 해제해줍니다. PATH 설정원하는 위치로 해당 디렉토리를 옮겨준 후 Path를 설정해줍니다. 1234567vi ~/.zshrc # set maven path export M2_HOME=/Users/bigdata/apache-maven-3.8.4 #maven 주소 / 사람마다 다르므로 변경해줘야함 export PATH=$PATH:$M2_HOME/binsource ~/.zshrc 설치 확인mvn -version 명령어를 통해 메이븐이 제데로 설치되었는지 확인한다.","link":"/2022/01/17/How-to-install-Maven-on-M1/"},{"title":"Hadoop HDFS fs Command Error","text":"하둡 HDFS 명령어란하둡은 사용자가 HDFS를 쉽게 제어할 수 있게 shell 명령어를 제공합니다. 이 shell 명령어는 fs(FileSystem Shell)라고 하며 아래와 같이 사용하게 됩니다. 1234./bin/hadoop fs -[cmd] [args]# PATH setting이 된 경우hadoop fs -[cmd] [args] 에러가 뜨는 경우 (WARNING은 해당사항 X)일단 당연하게도 에러가 발생했을때, 해당 에러명을 복사해서 구글링을 해보는 방법이 첫번째 입니다. 그래도 해결되지 않는 경우에 최후의 수단으로 아래와 같은 방법을 통하여 namenode를 format해버리는 방법이 있습니다. 1234567891011# hadoop를 실행중이라면 종료stop-all.sh# namenode formathadoop namenode -format# 하둡 실행start-all.sh# 명령어 작동 확인hadoop fs -[명령어] [파라미터]","link":"/2022/01/18/Hadoop-fs-ERROR/"}],"tags":[{"name":"hadoop","slug":"hadoop","link":"/tags/hadoop/"},{"name":"retrospect","slug":"retrospect","link":"/tags/retrospect/"}],"categories":[{"name":"hadoop","slug":"hadoop","link":"/categories/hadoop/"}]}